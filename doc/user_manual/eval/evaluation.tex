\chapter{Evaluation}
\label{sec:eval} 

The 'Evaluation' tab allows adapting/defining requirement-based standards and compliance assessment of said standards. \\

\section{Pre-Requisites \& Limitations}
\label{sec:eval_prereq} 

\begin{itemize}  
\item Target report associations must be set (using \nameref{sec:reconst})
\item At least 1 sector has to be defined (using \nameref{sec:ui_configure_sectors})
\item Usable reference data must exist
\item Usable test data must exist
\end{itemize}
\ \\

While it is possible to manually remove single targets from the evaluation, the usage of correct reference data is paramount for the significance of the evaluation results. \\

\includegraphics[width=0.5cm]{../../data/icons/hint.png} \textbf{Please note that the evaluation feature should not be used as a sole basis for decision making - especially not without manually verifying the evaluation results.}

\subsection{Sector Altitude Filtering}

If sectors with altitude limits are used, please be aware that target reports without a Mode C code can not be filtered by the set limit. Therefore such target reports are assumed to be inside in all 
sectors when inside the defined 2D polygons. \\

The 'inside-sector' check is always performed on the reference data only, therefore it is of importance to only use reference data with existing Mode C code data.

\subsection{Reference Data}

The assumption used in the tool is that the reference data is always correct. Therefore, sub-optimal reference data can cause errors, which will be attributed to the test data in the evaluation. \\

To give a few examples what this could mean:
\begin{itemize}  
\item Wrong 'inside-sector' check results: This might remove valid test data from the evaluation and/or attribute errors to the wrong sector
\item Missing target data in reference: This will remove the test data from evaluation for the time-period of the missing reference data
\item Wrong position in reference: This will cause wrong 'inside-sector' check results and/or cause wrong horizontal position accuracy results
\item Wrong/missing Mode C code in reference: This will cause wrong 'inside-sector' check results
\item Wrong/missing identification in reference: This will cause wrong results in identification requirements
\end{itemize}
\ \\

Also, since target secondary attributes are used in the 'Reconstruct References' task, errors in these attributes might also lead to imperfect data association, which could in turn result in wrong evaluation results in some requirements.

\section{Overview}
\label{sec:eval_overview} 

\begin{figure}[H]
    \hspace*{-2.5cm}
    \includegraphics[width=19cm]{figures/eval_overview.png}
  \caption{Evaluation dialog}
\end{figure}

When selecting \textit{Process $\rightarrow$ Evaluate} in the Main Menubar, the Evaluation dialog opens. \\

At the top, 4 tabs exist:
\begin{itemize}  
\item Main: Main configuration
\item Filter: Filter which data is loaded, by time and/or ADS-B quality indicators
\item Standard: Definition of standards, selection of current standard, configuration of requirements to be checked
\item Results Config: Additional configuration for the result generation
\end{itemize}
\ \\

Pressing the 'Run' button at the bottom will run the Evaluation, and generate a new Evaluation report.

\section{Configuration}
\label{sec:eval_config} 

\subsection{Main Tab}

\begin{figure}[H]
  \hspace*{-2cm}
    \includegraphics[width=18cm,frame]{figures/eval_main.png}
  \caption{Evaluation Main tab}
\end{figure}

In the 'Main' tab, the main configuration settings can be set. \\

\subsubsection{Data Selection}

At the top, the 'Data Selection' can be performed, by selecting:
\begin{itemize}  
\item Reference Data:
\begin{itemize}  
\item DBContent: Any DBContent existing in the database
\item Data source checkboxes: Which data sources to use
\item Line ID: Which line to use from the data sources
\end{itemize}
\item Test Data:
\begin{itemize}  
\item DBContent: Any DBContent existing in the database
\item Data source checkboxes: Which data sources to use
\item Line ID: Which line to use from the data sources
\end{itemize}
\end{itemize}
\ \\

As noted before, usage of appropriate reference data is of paramount importance. \\

Since 'any' type of data can be selected for evaluation, this allows for the following use-cases:
\begin{itemize}  
\item Tracker as reference, sensor as test data: Evaluation of sensor
\item Tracker as reference, tracker as test data: Evaluation/comparison of different trackers/tracker runs
\end{itemize}
\ \\

Of course it is also possible to use e.g. an imported GPS trail as reference (see \nameref{sec:ui_import_gps}), although this is currently not tested for lack of test data. 
If you might be able to provide such test data, please contact the author. \\

\subsubsection{Standard}
In the center, using the 'Standard' drop-down menu, the current standard can be selected. To create/configure the standard please use the 'Standard' tab.

\subsubsection{Minimum Height Filter}

The option 'Sector Layers: Minimum Height Filter' can be used to select a sector layer, which then serves as a complex minimum height filter.
The selected layer may consist of several sectors with configured minimum altitude, and data which does not lie inside the bounds and above the minimum altitude 
of at least one of the selected layer's sectors will automatically be treated as if residing outside of any evaluation sector. 
The filter thus acts as an additional precondition for data to be regarded by the evaluation.

\subsubsection{Sector Layer/Requirement Mapping}

Below that, the 'Sector Layers: Requirement Groups Usage' allows to define which requirements should be verified for which sector layer. \\

On the left, all existing sector layers are listed, in the shown example:
\begin{itemize}  
\item fir\_cut\_sim: DOI altitude limitation
\end{itemize}
\ \\

For each sector layer, the requirement groups (defined in the Standard tab) can be active/disabled. In the shown example, the existing requirement group 'Mandatory' is active in the sector layer. \\

\textbf{Note}: When selecting a minimum height filter, it usually makes no sense to evaluate requirements in this layer.
All requirement mappings thus should be deselected for this layer (see figure below).

\begin{figure}[H]
  \hspace*{-2cm}
    \includegraphics[width=18cm,frame]{figures/eval_unmap_min_height_filter.png}
  \caption{Minimum Height Filter}
\end{figure}

\subsection{Filter Tab}

\begin{figure}[H]
  \hspace*{-2cm}
    \includegraphics[width=18cm,frame]{figures/eval_filter.png}
  \caption{Evaluation Filter tab}
\end{figure}

In the Filter tab, what data is loaded for evaluation can be filtered \\

Below, the following elements exist:
\begin{itemize}  
\item 'Use Load Filter': Toggles usage of the load filter
\item 'Use RefTraj Accuracy Filter: Toggles usage of the minimum accuracy filter for DBContent RefTraj
\item 'Use ADS-B Filter: Toggles usage of the ADS-B filter
\item 'Use v0: Toggles usage of MOPS Version 0
\item 'Use Min NUCp: Toggles usage of the minimum NUCp value filter
\item 'Use Max NUCp: Toggles usage of the maximum NUCp value filter
\item 'Use v1: Toggles usage of MOPS Version 1
\item 'Use v2: Toggles usage of MOPS Version 2
\item 'Use Min NIC: Toggles usage of the minimum NIC value filter
\item 'Use Max NIC: Toggles usage of the maximum NIC value filter
\item 'Use Min NACp: Toggles usage of the minimum NACp value filter
\item 'Use Max NACp: Toggles usage of the maximum NACp value filter
\item 'Use Min SIL v1: Toggles usage of the minimum SIL v1 value filter
\item 'Use Max SIL v1: Toggles usage of the maximum SIL v1 value filter
\item 'Use Min SIL v2: Toggles usage of the minimum SIL v2 value filter
\item 'Use Max SIL v2: Toggles usage of the maximum SIL v2 value filter
\end{itemize}
\ \\

\subsection{Standard Tab}

\begin{figure}[H]
  \hspace*{-2cm}
    \includegraphics[width=18cm,frame]{figures/eval_standard.png}
  \caption{Evaluation Standard tab}
\end{figure}

In the Standard tab, at the top the current standard can be selected. \\

Below, the following buttons exist:
\begin{itemize}  
\item Add: Add a new standard with a unique name
\item Rename: Rename the current standard
\item Copy: Copy the current standard to a new one
\item Remove: Delete current standard
\end{itemize}
\ \\

At the bottom, the 'Reference Maximum Time Difference [s]' field can be edited to adjust the maximum time difference between reference updates. This value is used to find time-adjacent reference target reports for test target reports. Please adjust this value to e.g. the reference update period plus 1 second. \\

Currently, the following standards are (partly) supported:
\begin{itemize}  
\item EUROCAE ED-116 (\href{https://eshop.eurocae.net/eurocae-documents-and-reports/ed-116/}{Link})
\item EUROCAE ED-117/A (\href{https://eshop.eurocae.net/eurocae-documents-and-reports/ed-117a/}{Link})
\item EUROCAE ED-87C/E (\href{https://eshop.eurocae.net/eurocae-documents-and-reports/ed-87c/}{Link})
\item EUROCAE ED-142 (\href{https://eshop.eurocae.net/eurocae-documents-and-reports/ed-142/}{Link})
\item Radar: EUROCONTROL Standard Document for Radar Surveillance in En-Route Airspace and Major Terminal Areas (\href{https://www.eurocontrol.int/sites/default/files/publication/files/surveillance-standard-document-for-radar-surveillance-in-en-route-airspace-and-major-terminal-areas199703.pdf}{Link})
\end{itemize}
\ \\

Please note that, while the EUROCAE ED-117A has been tested using simulator data, the following limitations exist:
\begin{itemize}  
\item In the Stands area, the position accuracy should be calculated using a 5 second position averaging. This is currently not performed, since the averaging method is not specified, and is currently being discussed with users.
\item Some MLAT sensors use a different update rate for non-moving targets. This is currently not regarded, since what constitutes non-movement is not (generally) specified, and will lower the probability of detection.
\end{itemize}
\ \\

Please note that these limitations will be corrected in the near future. \\ 

The other standards have not yet been tested to the fullest degree, which is work in progress.

\subsubsection{Current Standard}

Below that, the current standard is shown. On the left side, a tree-view exists showing:
\begin{itemize}  
\item Standard name
\begin{itemize}  
\item Requirement Group(s)
\begin{itemize}  
\item Requirement(s)
\end{itemize}
\end{itemize}
\end{itemize}
\ \\

\begin{figure}[H]
  \hspace*{-2cm}
    \includegraphics[width=18cm,frame]{figures/eval_standard_add_req.png}
  \caption{Evaluation Standard tab: Add requirement}
\end{figure}

When clicking on the standard name, a menu is shown allowing adding new requirement groups ('Add Group'). \\

When clicking on a requirement group, a menu is shown allowing the following functions:
\begin{itemize}  
\item Delete Group: Delete the selected requirement group
\item Add Requirement: Add a requirement of the selected type
\item Delete Requirement: Delete the selected requirement
\end{itemize}
\ \\

The following requirements exist:

\begin{center}
 \begin{table}[H]
  \begin{tabularx}{\textwidth}{ | l | X |  }
    \hline
    \textbf{Type} & \textbf{Description} \\ \hline
    \nameref{sec:eval_req_accel_correct} & Calculates probability of correct acceleration \\ \hline
    \nameref{sec:eval_req_trk_coast_correct} & Calculates probability of correct track coasting flag \\ \hline
    \nameref{sec:eval_req_detection} & Calculates probability of detection  \\ \hline
    \nameref{sec:eval_req_dubious_targets} & Calculates probability of dubious targets based on physical movement (based on test data only) \\ \hline
    \nameref{sec:eval_req_dubious_tracks} & Calculates probability of dubious tracks from Trackers (based on test data only) \\ \hline
    \nameref{sec:eval_req_extra_data} & Calculates probability of unused test data (based on test data only) \\ \hline
    \nameref{sec:eval_req_extra_track} & Calculates probability of undetected tracks (based on reference data only) \\ \hline
    \nameref{sec:eval_req_id_correct} & Calculates probability of correct secondary identification \\ \hline
    \nameref{sec:eval_req_id_correct_periods} & Calculates probability of correct secondary identification based on UIs \\ \hline
    \nameref{sec:eval_req_id_false} & Calculates probability of false secondary identification \\ \hline
    \nameref{sec:eval_req_mom_long} & Calculates probability of correct MoM Longitudinal Acceleration \\ \hline
    \nameref{sec:eval_req_mom_trans} & Calculates probability of correct MoM Transversal Acceleration \\ \hline
    \nameref{sec:eval_req_mom_vert} & Calculates probability of correct MoM Vertical Rate \\ \hline
    \nameref{sec:eval_req_m3a_false} & Calculates probability of false Mode 3/A code \\ \hline
    \nameref{sec:eval_req_m3a_present} & Calculates probability of Mode 3/A code present \\ \hline
    \nameref{sec:eval_req_mc_correct} & Calculates probability of correct Mode C code \\ \hline
    \nameref{sec:eval_req_mc_correct_periods} & Calculates probability of correct Mode C code based on UIs \\ \hline
    \nameref{sec:eval_req_mc_false} & Calculates probability of false Mode C code \\ \hline
    \nameref{sec:eval_req_mc_present} & Calculates probability of Mode C code present \\ \hline
    \nameref{sec:eval_req_pos_across} & Calculates the probability of the position across error being within a threshold \\ \hline
    \nameref{sec:eval_req_pos_along} & Calculates the probability of the position along error being within a threshold \\ \hline
    \nameref{sec:eval_req_pos_distance} & Calculates the probability of the position error being within or outside a threshold \\ \hline
    \nameref{sec:eval_req_pos_distance_rms} & Calculates the probability of the position error being within or outside an RMS threshold \\ \hline
    \nameref{sec:eval_req_pos_latency}  & Calculates the probability of the position latency being within a threshold \\ \hline
    \nameref{sec:eval_req_pos_radar_azm} & Calculates the probability of the position azimuth error being within or outside a threshold \\ \hline
    \nameref{sec:eval_req_pos_radar_rng} & Calculates the probability of the position range error being within or outside a threshold \\ \hline
    \nameref{sec:eval_req_rocd_correct} & Calculates the probability of correct ROCD \\ \hline
    \nameref{sec:eval_req_speed} & Calculates the probability of the speed error being within or outside a threshold or percentage \\ \hline
    \nameref{sec:eval_req_track_angle} & Calculates the probability of correct track angle \\ \hline
\end{tabularx}
\end{table}
\end{center}
\ \\

If a requirement is clicked, it's configuration widget is shown on the right hand side. \\

Each requirement has the following common attributes:
\begin{itemize}  
\item Type: Type of the requirement
\item Name: Name of the requirement
\item Short Name: Abbreviated name of the requirement
\item Comment: Any text comment, e.g. reference to source document
\item Probability [1]: Probability threshold, as [0,1]
\item Probability Check Type: Probability comparison type for calculated probability against probability threshold
\end{itemize}
\ \\

For detailed information about each requirement please refer to section \nameref{sec:eval_requirements}.

\subsection{Results Config Tab}

\begin{figure}[H]
  \hspace*{-2cm}
  \center
    \includegraphics[width=12cm,frame]{figures/eval_results_config.png}
  \caption{Evaluation Results tab}
\end{figure}

The following settings can be used to configure the content of the generated results:

\begin{itemize}  
\item Skip No Data Details: Skip per target report details if no evaluated data existed (recommended)
\item Split Results by MOPS Version: Split sector aggregations also by ADS-B MOPS Versions (unknown,V0,V1,V2)
\item Split Results by Mode A/C Only and Mode S: Split sector aggregations also by Mode A/C Only and Mode S results
%\item Show ADS-B Info: Show ADS-B MOPS Version in results target lists
\item Show OK data in Sector Results: Show also OK markings in sector aggregations (not only errors)
\item Results Detail WGS84 Zoom Factor: Zoom factor in Geographic View for target report details
\item Grid Cells X: X-resolution of generated sector overview grids
\item Grid Cells Y: Y-resolution of generated sector overview grids
\end{itemize}
\ \\

\subsection{Evaluation}
\label{sec:eval_run_eval} 

After configuration, the evaluation can be run using the 'Run' button. \\

This will trigger evaluation of the requirements in all sectors (as configured). 
The requirement values will be calculated for each target (whether to be used or not). 
Then, for each requirement and sector, the results are summed-up as per-sector average (if target should be used). \\

Please note that the post-processing step uses all available cores on the CPU.

\begin{figure}[H]
  \centering 
    \includegraphics[width=10cm]{figures/eval_eval_status.png}
  \caption{Evaluation: Running evaluation status}
\end{figure}

\subfile{eval_inspect}
\subfile{eval_targets}
\subfile{eval_requirements}
